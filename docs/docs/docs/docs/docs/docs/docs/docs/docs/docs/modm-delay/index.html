<!DOCTYPE html> <html lang="en-US"> <head prefix="og: http://ogp.me/ns#"> <meta charset="UTF-8" /> <meta http-equiv="X-UA-Compatible" content="ie=edge" /> <meta name="viewport" content="width=device-width, initial-scale=1.0" /> <meta name="mobile-web-app-capable" content="yes" /> <meta name="apple-mobile-web-app-capable" content="yes" /> <meta name="application-name" content="embedded entanglement" /> <meta name="apple-mobile-web-app-status-bar-style" content="#fff" /> <meta name="apple-mobile-web-app-title" content="embedded entanglement" /> <title> Accurate Micro- and Nanosecond Delay in modm - embedded entanglement </title> <link rel="alternate" href="http://blog.salkinium.com/modm-delay/" hreflang="en-US" /> <link rel="canonical" href="http://blog.salkinium.com/modm-delay/" /> <meta name="description" content="reflecting on embedded software development" /> <meta name="referrer" content="no-referrer-when-downgrade" /> <meta property="fb:app_id" content="" /> <meta property="og:site_name" content="Accurate Micro- and Nanosecond Delay in modm | Niklas Hauser" /> <meta property="og:title" content="Accurate Micro- and Nanosecond Delay in modm | Niklas Hauser" /> <meta property="og:type" content="website" /> <meta property="og:url" content="http://blog.salkinium.com/modm-delay/" /> <meta property="og:description" content="reflecting on embedded software development" /> <meta property="og:image" content="" /> <meta property="og:image:width" content="640" /> <meta property="og:image:height" content="640" /> <meta name="twitter:card" content="summary" /> <meta name="twitter:title" content="Accurate Micro- and Nanosecond Delay in modm | salkinium" /> <meta name="twitter:url" content="http://blog.salkinium.com/modm-delay/" /> <meta name="twitter:site" content="@salkinium" /> <meta name="twitter:creator" content="@salkinium" /> <meta name="twitter:description" content="reflecting on embedded software development" /> <meta name="twitter:image" content="" /> <link type="application/atom+xml" rel="alternate" href="http://blog.salkinium.com/feed.xml" title="embedded entanglement" /> <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png" /> <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png" /> <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png" /> <link rel="manifest" href="/assets/favicons/site.webmanifest" /> <link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#5bbad5" /> <meta name="apple-mobile-web-app-title" content="Jekyll Klise" /> <meta name="application-name" content="Jekyll Klise" /> <meta name="msapplication-TileColor" content="#da532c" /> <meta name="theme-color" content="#2c2c2c" /> <link rel="stylesheet" href="/assets/css/style.css" /> </head> <body data-theme="dark" class="notransition"> <script> const body = document.body; const data = body.getAttribute("data-theme"); const initTheme = (state) => { if (state === "dark") { body.setAttribute("data-theme", "dark"); } else if (state === "light") { body.removeAttribute("data-theme"); } else { localStorage.setItem("theme", data); } }; initTheme(localStorage.getItem("theme")); setTimeout(() => body.classList.remove("notransition"), 75); </script> <div class="navbar" role="navigation"> <nav class="menu"> <input type="checkbox" id="menu-trigger" class="menu-trigger" /> <label for="menu-trigger"> <span class="menu-icon"> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 512 512" > <path d="M64,384H448V341.33H64Zm0-106.67H448V234.67H64ZM64,128v42.67H448V128Z" /> </svg> </span> </label> <a id="mode"> <svg class="mode-sunny" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 512 512" > <title>LIGHT</title> <line x1="256" y1="48" x2="256" y2="96" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="256" y1="416" x2="256" y2="464" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="108.92" x2="369.14" y2="142.86" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="369.14" x2="108.92" y2="403.08" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="464" y1="256" x2="416" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="96" y1="256" x2="48" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="403.08" x2="369.14" y2="369.14" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="142.86" x2="108.92" y2="108.92" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <circle cx="256" cy="256" r="80" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> </svg> <svg class="mode-moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 512 512" > <title>DARK</title> <line x1="256" y1="48" x2="256" y2="96" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="256" y1="416" x2="256" y2="464" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="108.92" x2="369.14" y2="142.86" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="369.14" x2="108.92" y2="403.08" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="464" y1="256" x2="416" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="96" y1="256" x2="48" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="403.08" x2="369.14" y2="369.14" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="142.86" x2="108.92" y2="108.92" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <circle cx="256" cy="256" r="80" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> </svg> </a> <div class="trigger"> <div class="trigger-container"><a class="menu-link" href="/">home</a><a class="menu-link" href="/archive/">archive</a><a class="menu-link" href="https://salkinium.com" target="_blank" rel="noopener" >about</a ><a class="menu-link rss" href="/feed.xml"> <svg xmlns="http://www.w3.org/2000/svg" width="17" height="17" viewBox="0 0 512 512" fill="#ED812E" > <title>RSS</title> <path d="M108.56,342.78a60.34,60.34,0,1,0,60.56,60.44A60.63,60.63,0,0,0,108.56,342.78Z" /> <path d="M48,186.67v86.55c52,0,101.94,15.39,138.67,52.11s52,86.56,52,138.67h86.66C325.33,312.44,199.67,186.67,48,186.67Z" /> <path d="M48,48v86.56c185.25,0,329.22,144.08,329.22,329.44H464C464,234.66,277.67,48,48,48Z" /> </svg> </a> </div> </div> </nav> </div> <div class="wrapper post"> <main class="page-content" aria-label="Content"> <article itemscope itemtype="https://schema.org/BlogPosting"> <header class="header"> <h1 class="header-title" itemprop="headline">Accurate Micro- and Nanosecond Delay in modm</h1> <div class="post-meta"> <time datetime="2021-07-05T00:00:00+02:00" itemprop="datePublished"> Jul 05, 2021 </time> <span itemprop="author" itemscope itemtype="https://schema.org/Person"> <span itemprop="name">Niklas Hauser</span> </span> <time hidden datetime="" itemprop="dateModified"> Jul 05, 2021 </time> <span hidden itemprop="publisher" itemtype="Person">Niklas Hauser</span> <span hidden itemprop="image"></span> <span hidden itemprop="mainEntityOfPage"><p>Accurately spinning for short and long time durations is an essential part of an embedded application. In the <a href="https://modm.io">modm embedded library</a> we provide blocking delay functions in the resolution of milli-, micro- and even nanoseconds. Let’s have a look at how we used the available hardware to implement a fast, efficient and flexible API that’s used in thousands of devices all with different clock configurations.</p> <p>The most prominent uses for blocking delays in modm are during initialization of internal peripherals and external drivers that may require a few micro- to milliseconds to stabilize their hardware, and when bit-banging protocols in software with kHz and MHz baudrates requiring micro- or even nanosecond delay.</p> <p>The delay functions must be accurate, in particular they must have the shortest possible overhead and a low error over at least 1s of delay time. They need to already work during the global constructor calls and remain accurate if the clock configuration and therefore the CPU frequency (dynamically) changes and they must be reentrant so they can be called from inside an interrupt if needed. And lastly they should be compatible with the <code class="language-plaintext highlighter-rouge">std::chrono</code> time units, so that we can pass them literals for ease of use:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">1s</span><span class="p">);</span>      <span class="c1">// non-literal version</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">10ms</span><span class="p">);</span>    <span class="n">modm</span><span class="o">::</span><span class="n">delay_ms</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">100us</span><span class="p">);</span>   <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">1000ns</span><span class="p">);</span>  <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span>
</code></pre></div></div> <h1 id="computing-cycles">Computing Cycles</h1> <p>The simplest delay function converts the input time to CPU cycles and then spins in place counting them down. For the conversion we need to know the CPU frequency and have some mechanism for keeping track of elapsed CPU cycles.</p> <p>For microsecond and longer delays the conversion is simple: 1µs = 1MHz<sup>-1</sup>, so you can just take the CPU frequency in MHz and multiply it with the input to get the cycles. We store the frequency in a global <code class="language-plaintext highlighter-rouge">uint16_t</code> already scaled down to MHz and initialized with the boot frequency during startup.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// microcontroller boots with a 8MHz clock</span>
<span class="kt">uint16_t</span> <span class="n">fcpu_MHz</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
<span class="c1">// simple conversion with multiplication</span>
<span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">us</span> <span class="o">*</span> <span class="n">fcpu_MHz</span><span class="p">;</span>
</code></pre></div></div> <p>This works well for frequencies that divide 1MHz cleanly, however, the STM32L0/L1 microcontrollers boot at 2.097MHz for example, which results in a 5% error right after boot. We therefore binary scale the MHz value to achieve a much lower error, which can be done very efficiently with bit shifting:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// multiply MHz with power-of-two 2^5 = 32</span>
<span class="k">constexpr</span> <span class="kt">uint8_t</span> <span class="n">shift</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
<span class="c1">// 2.097MHz * 32  -&gt;  67 = 2.09375MHz  -&gt;  ~0.2% error</span>
<span class="n">constinit</span> <span class="kt">uint16_t</span> <span class="n">fcpu_MHz</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">round</span><span class="p">(</span><span class="mf">2.097</span><span class="n">f</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1ul</span> <span class="o">&lt;&lt;</span> <span class="n">shift</span><span class="p">));</span>
<span class="c1">// divide with simple bit shift</span>
<span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">us</span> <span class="o">*</span> <span class="n">fcpu_MHz</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">shift</span><span class="p">;</span>
</code></pre></div></div> <p>To keep the 32-bit multiplication from overflowing and to maintain at least 1s = 1’000’000µs of delay, we must limit the scaling so that 2<sup>32 - shift</sup> / max_fcpu ≥ 1s. A scalar of 32 is only good up to 134MHz, while the fastest STM32H7 running at 480MHz limits the scalar to only 8.</p> <p>For nanosecond delay we need a different algorithm, since the microcontrollers all run below 1GHz so one CPU cycle is several nanoseconds long. For example, the STM32F7 runnning at 216MHz will take ~4.6ns per cycle. To get the cycles fron a nanosecond input we would need to <em>divide</em>:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">float</span> <span class="n">ns_per_cycle</span> <span class="o">=</span> <span class="mf">4.6</span><span class="n">f</span><span class="p">;</span>
<span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">/</span> <span class="n">ns_per_cycle</span><span class="p">;</span>
</code></pre></div></div> <p>This is obviously way too slow to compute, but we first need to understand how to accurately <em>count</em> cycles to find a better solution to this problem.</p> <h1 id="counting-cycles">Counting Cycles</h1> <p>Wouldn’t it be nice if we could just delegate counting cycles to some hardware counter? Well, look no further than the Data Watchpoint and Trace (DWT) peripheral and its 32-bit <code class="language-plaintext highlighter-rouge">CYCCNT</code> free running at CPU frequency!</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Enable Tracing Debug Unit</span>
<span class="n">CoreDebug</span><span class="o">-&gt;</span><span class="n">DEMCR</span> <span class="o">|=</span> <span class="n">CoreDebug_DEMCR_TRCENA_Msk</span><span class="p">;</span>
<span class="c1">// Enable CPU cycle counter</span>
<span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CTRL</span> <span class="o">|=</span> <span class="n">DWT_CTRL_CYCCNTENA_Msk</span><span class="p">;</span>
</code></pre></div></div> <p>By reading <code class="language-plaintext highlighter-rouge">DWT-&gt;CYCCNT</code> once at the beginning and then comparing this constantly in a loop until the number of cycles have passed, we can implement a very simple, yet fairly accurate delay function:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">us</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">fcpu_MHz</span> <span class="o">*</span> <span class="n">us</span> <span class="o">&gt;&gt;</span> <span class="n">shift</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">now</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">now</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&gt;=</span> <span class="n">cycles</span><span class="p">)</span> <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Bonus win for this solution: time spent in interrupts during the delay is compensated for, since the hardware counter continues counting throughout.</p> <p>The delay function we use in modm only adds a memory fence to ensure reading the <code class="language-plaintext highlighter-rouge">start</code> count is not interleaved with other instructions and an overflow check when compiled in debug mode using <code class="language-plaintext highlighter-rouge">__builtin_umul_overflow</code> which triggers a <code class="language-plaintext highlighter-rouge">modm_assert</code>.</p> <h1 id="counting-loops">Counting Loops</h1> <p>Unfortunately, the <code class="language-plaintext highlighter-rouge">DWT</code> peripheral is not implemented on ARM Cortex-M0(+) aka. ARMv6-M, so we have to count cycles a different way. We could use the <code class="language-plaintext highlighter-rouge">SysTick-&gt;VAL</code>, however it’s just a 24-bit counter, which limits us to ~16.8 million cycles: a ~1s delay at 16MHz or a maximum 35ms delay (!) at 480MHz. The SysTick is also often used for preemptive scheduling (in FreeRTOS) or to create a global clock (for software timers), so we cannot use it as a replacement.</p> <p>Instead we will count cycles the old fashioned way: in a tight assembly loop with a known timing. We use two 16-bit Thumb-2 instructions: subtraction and branch back. They are aligned so they fit into a single 32-bit instruction fetch and fill the pipeline entirely, giving us the maximum performance: 1 cycle for the subtraction and 2-cycles to branch back, so the loop takes 3 cycles total:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">us</span><span class="p">)</span> <span class="n">modm_fastcode</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">fcpu_MHz</span> <span class="o">*</span> <span class="n">us</span> <span class="o">&gt;&gt;</span> <span class="n">shift</span><span class="p">;</span>
    <span class="k">asm</span> <span class="k">volatile</span> <span class="p">(</span>
        <span class="s">".align 4"</span>          <span class="c1">// align for *one* 32-bit instruction fetch</span>
    <span class="s">"1:  subs.n %0, %0, #3"</span> <span class="c1">// subtract the loop cycles</span>
        <span class="s">"bpl.n  1b"</span>         <span class="c1">// loop while cycles are positive</span>
    <span class="o">::</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">cycles</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div> <p>The instruction fetch timings for executing directly from Flash depends on the CPU speed, the currently configured wait states and the state of the cache (if available and configured) and finally the branch speculation of the vendor cache implementation (this is not a core feature!). We therefore place the entire function into SRAM using the <code class="language-plaintext highlighter-rouge">modm_fastcode</code> attribute, which gives us <em>predictable</em> timings for instruction fetches across all Cortex-M cores, since we’re bypassing the Flash wait states and the (vendor supplied) cache entirely.</p> <p>Predictable, but not consistent: In my experiments I’ve discovered the loop to take 3 cycles on STM32{F3, G0, G4, L0, L4}, 4 cycles on STM32{L1, F0, F1, F4, F2} and just 1 cycle (yes!) on STM32F7. The timings depend on the (vendor defined) bus matrix implementation and the system configuration and are mainly about whether the Instruction Bus (I-Code) can access SRAM directly or whether the access is performed by the slower System Bus (S-Bus). The STM32F4 reference manual states in section 2.3.1 Embedded SRAM:</p> <blockquote> <p>The CPU can access the SRAM1, SRAM2, and SRAM3 through the System Bus or through the I-Code/D-Code buses when boot from SRAM is selected or when physical remap is selected. To get the max performance on SRAM execution, physical remap should be selected (boot or software selection).</p> </blockquote> <p>It seems that access through the I-Code takes 2-cycles, but the S-Bus takes 4-cycles, while the Cortex-M7 has a dual issue pipeline and native instruction cache with native branch prediction, so it’s just… really fast ? As confusing as it might be, at least the instruction fetch timing from SRAM is independent from the configured CPU frequency, which allows us to hardcode the loop cycles to subtract as an immediate value encoded in the instruction.</p> <p>The upper bound on the error is at most 3 cycles plus the error of the binary scaling, which together is good enough for our purpose. However, interrupts are not compensated, so the real delay may be significantly longer. If an accurate delay is absolutely necessary it can be wrapped into <code class="language-plaintext highlighter-rouge">modm::atomic::Lock</code> to disable interrupts during the delay.</p> <h1 id="counting-nanoseconds">Counting Nanoseconds</h1> <p>To delay for nanoseconds we need to do something a little different, since the naive approach involves division, which would be way too slow. We can, however, approximate this division with a loop of subtractions! So we input the nanoseconds into the <code class="language-plaintext highlighter-rouge">subs bpl</code> loop and subtract the nanoseconds each loop takes: 1-4 cycles * fcpu<sup>-1</sup>. We store this value in SRAM and update it on every clock change:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">constexpr</span> <span class="kt">uint8_t</span> <span class="n">cycles_per_loop</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span> <span class="c1">// depends on device</span>
<span class="c1">// round the nanoseconds to minimize error</span>
<span class="kt">uint16_t</span> <span class="n">ns_per_loop</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">round</span><span class="p">(</span><span class="mf">1e9</span> <span class="o">*</span> <span class="n">cycles_per_loop</span> <span class="o">/</span> <span class="n">fcpu</span><span class="p">);</span>

<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ns</span><span class="p">)</span> <span class="n">modm_fastcode</span>
<span class="p">{</span>
    <span class="k">asm</span> <span class="k">volatile</span> <span class="p">(</span>
        <span class="s">".align 4"</span>          <span class="c1">// align for *one* 32-bit instruction fetch</span>
    <span class="s">"1:  subs.n %0, %0, %1"</span> <span class="c1">// subtract the nanoseconds per loop</span>
        <span class="s">"bpl.n  1b"</span>         <span class="c1">// loop while nanoseconds are positive</span>
    <span class="o">::</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">ns_per_loop</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div> <p>This works, however, there is a large overhead until execution arrives at the loop. The reason is that the compiler uses a <code class="language-plaintext highlighter-rouge">bl</code> (branch and link) instruction to jump to an address encoded as an <em>immediate value</em>. This is fast and efficient, however, it limits us to a relative address range of ±4MBs and our delay function in SRAM is waaaaay out there (SRAM starts @0x20000000 vs Flash @0x08000000). So the linker has to add a veneer, that does nothing else but jump further:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        modm::delay_ns(ns);
 8000214:   f002 fbf4   bl  8002a00 &lt;___ZN4modm8delay_nsEm_veneer&gt;

08002a00 &lt;___ZN4modm8delay_nsEm_veneer&gt;:
 8002a00:   f85f f000   ldr.w   pc, [pc]    ; 8002a04
 8002a04:   20000189    .word   0x20000189

20000188 &lt;_ZN4modm8delay_nsEm&gt;:
void modm_fastcode modm::delay_ns(uint32_t us)
</code></pre></div></div> <p>Since Flash access is very slow (up to a dozen wait states for fast devices), vendors supply a cache implementation with a limited buffer size (the ST “ART accelerator” cache has a max size of just 256-bit = 32 bytes!). So the jump to the veneer spends many cycles just waiting on the Flash and this time depends on the current clock configuration. Can we do better? Yes, with inline assembly!</p> <p>We move the actual implementation to <code class="language-plaintext highlighter-rouge">modm::platform::delay_ns</code> and then use an forced-inline forwarding function that uses the <code class="language-plaintext highlighter-rouge">blx</code> instruction to jump there directly instead of through a veneer:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm_always_inline</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ns</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">asm</span> <span class="k">volatile</span><span class="p">(</span>
        <span class="s">"mov r0, %0"</span> <span class="c1">// Required for the calling convention</span>
        <span class="s">"blx %1"</span>     <span class="c1">// Jump there directly</span>
        <span class="o">::</span> <span class="s">"r"</span> <span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">modm</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">)</span> <span class="o">:</span> <span class="s">"r0"</span><span class="p">,</span> <span class="s">"r1"</span><span class="p">,</span> <span class="s">"r2"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>This reduces the overhead by eliminating the unnecessary jump and loading a literal that may already be in the instruction cache.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        modm::delay_ns(ns);
 80002c6:   4c25        ldr r4, [pc, #148]  ; 800035c
 80002ca:   4628        mov r0, r5
 80002cc:   47a0        blx r4

 800035c:   200001a9    .word   0x200001a9

200001a8 &lt;_ZN4modm8platform8delay_nsEm&gt;:
void modm_fastcode modm::platform::delay_ns(uint32_t us)
</code></pre></div></div> <p>However, we still need to actually compensate for this overhead, even if it’s just a few cycles, there should not be an offset in the delay function. To have maximum control we declare the function to be naked and implement the whole function in inline assembly:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">__attribute__</span><span class="p">((</span><span class="kr">naked</span><span class="p">,</span> <span class="n">aligned</span><span class="p">(</span><span class="mi">4</span><span class="p">)))</span> <span class="n">modm_fastcode</span>
<span class="n">modm</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ns</span><span class="p">)</span> <span class="c1">// passed in r0</span>
<span class="p">{</span>
    <span class="k">asm</span> <span class="k">volatile</span> <span class="p">(</span>
        <span class="s">"ldr.n  r2, =ns_per_loop"</span> <span class="c1">// address of ns_per_loop</span>
        <span class="s">"ldrh.n r2, [r2, #0]"</span>     <span class="c1">// load the actual 16-bit ns_per_loop value</span>

        <span class="s">"lsls.n r1, r2, #2"</span>       <span class="c1">// approximate overhead in ns by shift</span>
        <span class="s">"subs.n r0, r0, r1"</span>       <span class="c1">// subtract the overhead in nanoseconds</span>

    <span class="s">"1:  subs.n r0, r0, r2"</span>       <span class="c1">// subtract the nanoseconds per loop</span>
        <span class="s">"bpl.n  1b"</span>               <span class="c1">// loop while nanoseconds are positive</span>

        <span class="s">"bx lr"</span>                   <span class="c1">// return to execution</span>
    <span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>The overhead is measured experimentally and expressed in loops, which we can convert to nanoseconds by multiplying with the <code class="language-plaintext highlighter-rouge">ns_per_loop</code> variable. However the <code class="language-plaintext highlighter-rouge">umul</code> instruction requires passing the operands in registers, which would require an additional <code class="language-plaintext highlighter-rouge">mov</code> instruction for the <code class="language-plaintext highlighter-rouge">#4</code> immediate value, so instead we use the <code class="language-plaintext highlighter-rouge">lsl</code> instruction to shift the value left with the same effect. This limits the “overhead loop count” to powers of two, which in practice is not an issue.</p> <h1 id="counting-cycles-on-avr">Counting Cycles on AVR</h1> <p>AVRs cannot change their CPU frequency at runtime, instead it is fixed at compile time via the <code class="language-plaintext highlighter-rouge">F_CPU</code> macro, so we don’t have to worry about that. The avr-lib provide implementations of <code class="language-plaintext highlighter-rouge">_delay_ms(double)</code> and <code class="language-plaintext highlighter-rouge">_delay_us(double)</code> in the <a href="https://www.nongnu.org/avr-libc/user-manual/group__util__delay.html"><code class="language-plaintext highlighter-rouge">&lt;util/delay.h&gt;</code> header</a>: However, <a href="https://www.nongnu.org/avr-libc/user-manual/delay_8h_source.html">the implementations use floating point math to calculate the delay cycles</a> for dynamic arguments. But fear not for there is a very sternly worded warning for passing a dynamic value to this incredible foot gun:</p> <blockquote> <p>In order for these functions to work as intended, compiler optimizations must be enabled, and the delay time must be an expression that is a known constant at compile-time. If these requirements are not met, the resulting delay will be much longer (and basically unpredictable), and applications that otherwise do not use floating-point calculations will experience severe code bloat by the floating-point library routines linked into the application.</p> </blockquote> <p>Of course this is a completely unacceptable implementation, since avr-gcc provides <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"><code class="language-plaintext highlighter-rouge">__builtin_constant_p()</code></a> to detect constant arguments and together with <a href="https://gcc.gnu.org/onlinedocs/gcc/AVR-Built-in-Functions.html"><code class="language-plaintext highlighter-rouge">__builtin_avr_delay_cycles(uint32_t)</code></a> can generates very accurate delays down to a single cycle for constant inputs at any clock rate.</p> <p>For a delay with a runtime argument we can loop over a 1ms or 1us constant delay and compensate for the loop overhead:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm_always_inline</span> <span class="c1">// &lt;- must be force inlined to work</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ms</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ms</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">__builtin_constant_p</span><span class="p">(</span><span class="n">ms</span><span class="p">)</span> <span class="o">?</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">*</span> <span class="kt">double</span><span class="p">(</span><span class="n">ms</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">);</span>
        <span class="n">__builtin_avr_delay_cycles</span><span class="p">(</span><span class="n">cycles</span><span class="p">);</span>
    <span class="p">})</span> <span class="o">:</span> <span class="p">({</span>
        <span class="k">while</span><span class="p">(</span><span class="n">ms</span><span class="o">--</span><span class="p">)</span> <span class="n">__builtin_avr_delay_cycles</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">)</span> <span class="o">-</span> <span class="mi">10</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
<span class="n">modm_always_inline</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">us</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">__builtin_constant_p</span><span class="p">(</span><span class="n">us</span><span class="p">)</span> <span class="o">?</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">*</span> <span class="kt">double</span><span class="p">(</span><span class="n">us</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">);</span>
        <span class="n">__builtin_avr_delay_cycles</span><span class="p">(</span><span class="n">cycles</span><span class="p">);</span>
    <span class="p">})</span> <span class="o">:</span> <span class="p">({</span>
        <span class="c1">// slightly lower overhead due to 16-bit delay  vvv</span>
        <span class="k">while</span><span class="p">(</span><span class="n">us</span><span class="o">--</span><span class="p">)</span> <span class="n">__builtin_avr_delay_cycles</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span> <span class="o">-</span> <span class="mi">6</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
</code></pre></div></div> <p>For dynamic nanosecond delay we approximate the division again with a shift, however, this time without multiplication, since that operation is very expensive on AVRs (dozens of cycles). The shift value is computed at compile time by rounding to the nearest power-of-two. The result is passed to the 4-cycle <code class="language-plaintext highlighter-rouge">_delay_loop_2(uint16_t)</code>, which does the actual delay. This solution only yields accurate delays at 16MHz (shift 8), 8MHz (shift 9) and 4MHz (shift 10), and has a significant error plus additional overhead of a few cycles for shifts &gt; 8. It’s not an ideal solution, but all other ideas yielded significantly worse results incl. using the Cortex-M method of subtraction in a loop.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm_always_inline</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint16_t</span> <span class="n">ns</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">__builtin_constant_p</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span> <span class="o">?</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">*</span> <span class="kt">double</span><span class="p">(</span><span class="n">ns</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">);</span>
        <span class="n">__builtin_avr_delay_cycles</span><span class="p">(</span><span class="n">cycles</span><span class="p">);</span>
    <span class="p">})</span> <span class="o">:</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">loops</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">&gt;&gt;</span> <span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">loops</span><span class="p">)</span> <span class="n">_delay_loop_2</span><span class="p">(</span><span class="n">loops</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="using-stdchrono">Using std::chrono</h1> <p>We want these functions to be compatible with <code class="language-plaintext highlighter-rouge">using namespace std::chrono_literals</code> so we overload the <code class="language-plaintext highlighter-rouge">modm::delay()</code> function with the appropriate durations. The conversion gets completely inlined and optimized away, so even for dynamic arguments there’s no code generated. A notable exception is the millisecond delay on Cortex-M, which gets converted to microseconds via a fast multiplication.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">Rep</span><span class="p">&gt;</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">Rep</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">nano</span><span class="o">&gt;</span> <span class="n">ns</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="k">auto</span> <span class="n">ns_</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">nanoseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ns</span><span class="p">)};</span>
    <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="n">ns_</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="p">}</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">Rep</span><span class="p">&gt;</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">Rep</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">micro</span><span class="o">&gt;</span> <span class="n">us</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="k">auto</span> <span class="n">us_</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">us</span><span class="p">)};</span>
    <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="n">us_</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="p">}</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">Rep</span><span class="p">&gt;</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">Rep</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">milli</span><span class="o">&gt;</span> <span class="n">ms</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// converted to us on Cortex-M, but AVR just forwards to modm::delay_ms</span>
    <span class="k">const</span> <span class="k">auto</span> <span class="n">us</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ms</span><span class="p">)};</span>
    <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="n">us</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="evaluation">Evaluation</h1> <p>We can test the performance of our delay functions with <code class="language-plaintext highlighter-rouge">DWT-&gt;CYCCNT</code> on ARMv7-M which has a fixed 4 cycle overhead:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">time</span><span class="p">);</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// 4 cycles overhead</span>
</code></pre></div></div> <p>ARMv6-M has no DWT module, so we use the <code class="language-plaintext highlighter-rouge">SysTick-&gt;VAL</code> instead. The value counts down (!) and gets reloaded to <code class="language-plaintext highlighter-rouge">SysTick-&gt;RELOAD</code> on underrun. We need to make sure the underrun does not happen during measurement so we set the <code class="language-plaintext highlighter-rouge">SysTick-&gt;VAL</code>before it.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">VAL</span> <span class="o">=</span> <span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">RELOAD</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">VAL</span><span class="p">;</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">time</span><span class="p">);</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">VAL</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">start</span> <span class="o">-</span> <span class="n">stop</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// swapped subtraction!</span>
</code></pre></div></div> <p>And finally on AVRs we can use a 16-bit counter, here we use <code class="language-plaintext highlighter-rouge">TCNT1</code>, which limits the measurement (but not the delay function) to a maximum of 4ms @16MHz.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">TCNT1</span><span class="p">;</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">time</span><span class="p">);</span>
<span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">TCNT1</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">;</span>
</code></pre></div></div> <p>In total 19 devices were tested by passing the delay function dynamic arguments in 10ns steps from 0ns to 10000ns. The Cortex-M devices were tested once at boot frequency and then again at their highest frequency. The AVR implementation is inlined in Flash, while the Cortex-M implementation jumps into RAM or I-Cache.</p> <table> <thead> <tr> <th style="text-align: left">Device</th> <th style="text-align: left">Core Type</th> <th style="text-align: right">Cycles per Loop</th> <th style="text-align: center">Minimum Cycles at Boot/High Frequency</th> <th style="text-align: right">Minimum Delay at Boot Frequency</th> <th style="text-align: right">Minimum Delay at High Frequency</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">ATMEGA2560</td> <td style="text-align: left">avr8</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right"> </td> </tr> <tr> <td style="text-align: left">SAMD21</td> <td style="text-align: left">cm0+</td> <td style="text-align: right">3</td> <td style="text-align: center">15</td> <td style="text-align: right"> </td> <td style="text-align: right">312ns @ 48 MHz</td> </tr> <tr> <td style="text-align: left">STM32F072</td> <td style="text-align: left">cm0</td> <td style="text-align: right">4</td> <td style="text-align: center">18/19</td> <td style="text-align: right">1125ns @ 16 MHz</td> <td style="text-align: right">395ns @ 48 MHz</td> </tr> <tr> <td style="text-align: left">STM32F091</td> <td style="text-align: left">cm0</td> <td style="text-align: right">4</td> <td style="text-align: center">18/19</td> <td style="text-align: right">1125ns @ 16 MHz</td> <td style="text-align: right">395ns @ 48 MHz</td> </tr> <tr> <td style="text-align: left">STM32F103</td> <td style="text-align: left">cm3</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">2000ns @ 8 MHz</td> <td style="text-align: right">250ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32F303</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13</td> <td style="text-align: right">1625ns @ 8 MHz</td> <td style="text-align: right">203ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32F334</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13</td> <td style="text-align: right">1625ns @ 8 MHz</td> <td style="text-align: right">203ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32F401</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">190ns @ 84 MHz</td> </tr> <tr> <td style="text-align: left">STM32F411</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">166ns @ 96 MHz</td> </tr> <tr> <td style="text-align: left">STM32F429</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">95ns @ 168 MHz</td> </tr> <tr> <td style="text-align: left">STM32F446</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">88ns @ 180 MHz</td> </tr> <tr> <td style="text-align: left">STM32F469</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">88ns @ 180 MHz</td> </tr> <tr> <td style="text-align: left">STM32F746</td> <td style="text-align: left">cm7fd</td> <td style="text-align: right">1</td> <td style="text-align: center">19</td> <td style="text-align: right">1187ns @ 16 MHz</td> <td style="text-align: right">87ns @ 216 MHz</td> </tr> <tr> <td style="text-align: left">STM32G071</td> <td style="text-align: left">cm0+</td> <td style="text-align: right">3</td> <td style="text-align: center">16/18</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">281ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32G474</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">17</td> <td style="text-align: right">1062ns @ 16 MHz</td> <td style="text-align: right">100ns @ 170 MHz</td> </tr> <tr> <td style="text-align: left">STM32L031</td> <td style="text-align: left">cm0</td> <td style="text-align: right">4</td> <td style="text-align: center">16/17</td> <td style="text-align: right">7629ns @ 2.097 MHz</td> <td style="text-align: right">531ns @ 32 MHz</td> </tr> <tr> <td style="text-align: left">STM32L152</td> <td style="text-align: left">cm3</td> <td style="text-align: right">4</td> <td style="text-align: center">16/17</td> <td style="text-align: right">7629ns @ 2.097 MHz</td> <td style="text-align: right">531ns @ 32 MHz</td> </tr> <tr> <td style="text-align: left">STM32L432</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13/15</td> <td style="text-align: right">812ns @ 16 MHz</td> <td style="text-align: right">162ns @ 80 MHz</td> </tr> <tr> <td style="text-align: left">STM32L476</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13/15</td> <td style="text-align: right">812ns @ 16 MHz</td> <td style="text-align: right">312ns @ 48 MHz</td> </tr> </tbody> </table> <p>The absolute minimum delay we can achieve is ~90ns and only on devices with a fast clock. You can clearly see the effect of the additional flash wait-states on some devices when they switch to high frequency</p> <p><img invertible="" src="ns_boot.svg" /></p> <p>The graph of the expected against the measured nanosecond delay at boot frequency shows several interesting points:</p> <ul> <li>The above mentioned minimum delays are very clear, particularly the 7.6us minimum delay for the STM32L0 and STM32L1 which boot at only ~2MHz.</li> <li>A ~600ns offset on AVR: This is not surprising as our implementation does not compensate for the calling overhead at all.</li> <li>A percentual error on AVR: At 16MHz the correct divider would be 250 for a 4-cycle loop, however, we’re shifting 8 = divide by 256, which is a 2.5% error. For other frequencies this error will be much higher.</li> <li>An offset on STM32F7: The correct offset compensation would be ~26 loops, however our “shift multiplication” can only do 16 or 32 loops, hence this offset. The Cortex-M7 has built-in branch prediction, perhaps that explains the small irregularity at the beginning.</li> <li>The coarseness of the stepping very clearly shows the different clock speeds and the cycles per loop.</li> <li>Most implemementations follow the ideal delay line very closely.</li> </ul> <p><img invertible="" src="ns_high.svg" /></p> <p>The graph of the expected against the measured nanosecond delay at the highest frequency shows that all implementations follow the ideal delay very precisely with only a very small error.</p> <p>The notable exception is the STM32F7 implementation, which has no offset anymore, but a significant ~7.5% error over time. Running at 216MHz a 1-cycle loop takes ~4.6ns which gets rounded up to 5ns which is then subtracted on every 1-cycle loop, thus yielding the full ~7.5% error. This creates an interesting failure mode for this algorithm: At around 667MHz the error is highest at 50%, since a 1.5ns per loop (=1ns/667MHz) delay must be rounded to either 1ns or 2ns. Currently no STM32 runs at that high a speed, however, the STM32H7 can run at at 400MHz, where the error would still be 25%.</p> <p>The delay implementation other devices has the same problem, however, since the loop takes 3-4 cycles the error is much smaller. For example, the 3-cycle loop on the STM32G4 running at a comparable 170MHz takes ~17.6ns (=3ns/170MHz) ≈ 18ns per loop, which is an error of just ~2%. In contrast, the 4-cycle loop on the 64MHz STM32F1 takes 62.5ns (=4ns/64MHz) ≈ 63ns with an error of ~1%.</p> <p>It becomes clear that the subtraction spreads the rounding error over 3-4 cycles which is comparable to fractional integer division. So an easy fix for the 1-cycle loop error on the STM32F7 is to lengthen the loop with some NOPs to reduce the overall error at the cost of resolution. I will leave this for a future self to solve though.</p> <p><img invertible="" src="ns_high_detail.svg" /></p> <p>Finally a detailed version of nanosecond delay at high frequencies from 0ns to 1000ns shows the same minimum delay and stepping properties as the boot frequency graph, showing that the same code is producing the same results at a faster speed too.</p> <p><img invertible="" src="us_boot.svg" /></p> <p>For completeness we’ve also measured microsecond delay from 0us to 1000us at boot frequency. The results are very accurate with a minimum delay of 1us on all devices except on the STM32L0 and STM32L1. They boot at 2.097MHz, where we use the fractional multiplication and shift to approximate 2.125MHz with an error of ~2%. Unfortunately on these devices millisecond delay will also have a 2% error, since they use microsecond delay under the hood as discussed.</p> <p>For microsecond delay at high frequency the measurements show no deviation at all, so that the graph is just a boring 1:1 line and therefore omitted.</p> <p>In conclusion, very accurate delays even at nanosecond resolution on AVR and Cortex-M devices are possible if the call overhead is compensated and the error over time is bound. However, the delay implementations are not as trivial as expected, but with some simple tricks can be made to fit.</p> <p><a href="https://xkcd.com/598"><img invertible="" src="xkcd.png" /></a></p> </span> </div> </header> <div class="page-content" itemprop="articleBody"> <p>Accurately spinning for short and long time durations is an essential part of an embedded application. In the <a href="https://modm.io">modm embedded library</a> we provide blocking delay functions in the resolution of milli-, micro- and even nanoseconds. Let’s have a look at how we used the available hardware to implement a fast, efficient and flexible API that’s used in thousands of devices all with different clock configurations.</p> <p>The most prominent uses for blocking delays in modm are during initialization of internal peripherals and external drivers that may require a few micro- to milliseconds to stabilize their hardware, and when bit-banging protocols in software with kHz and MHz baudrates requiring micro- or even nanosecond delay.</p> <p>The delay functions must be accurate, in particular they must have the shortest possible overhead and a low error over at least 1s of delay time. They need to already work during the global constructor calls and remain accurate if the clock configuration and therefore the CPU frequency (dynamically) changes and they must be reentrant so they can be called from inside an interrupt if needed. And lastly they should be compatible with the <code class="language-plaintext highlighter-rouge">std::chrono</code> time units, so that we can pass them literals for ease of use:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">1s</span><span class="p">);</span>      <span class="c1">// non-literal version</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">10ms</span><span class="p">);</span>    <span class="n">modm</span><span class="o">::</span><span class="n">delay_ms</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">100us</span><span class="p">);</span>   <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="mx">1000ns</span><span class="p">);</span>  <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span>
</code></pre></div></div> <h1 id="computing-cycles"> <a href="#computing-cycles" class="anchor-head"></a> Computing Cycles </h1> <p>The simplest delay function converts the input time to CPU cycles and then spins in place counting them down. For the conversion we need to know the CPU frequency and have some mechanism for keeping track of elapsed CPU cycles.</p> <p>For microsecond and longer delays the conversion is simple: 1µs = 1MHz<sup>-1</sup>, so you can just take the CPU frequency in MHz and multiply it with the input to get the cycles. We store the frequency in a global <code class="language-plaintext highlighter-rouge">uint16_t</code> already scaled down to MHz and initialized with the boot frequency during startup.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// microcontroller boots with a 8MHz clock</span>
<span class="kt">uint16_t</span> <span class="n">fcpu_MHz</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
<span class="c1">// simple conversion with multiplication</span>
<span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">us</span> <span class="o">*</span> <span class="n">fcpu_MHz</span><span class="p">;</span>
</code></pre></div></div> <p>This works well for frequencies that divide 1MHz cleanly, however, the STM32L0/L1 microcontrollers boot at 2.097MHz for example, which results in a 5% error right after boot. We therefore binary scale the MHz value to achieve a much lower error, which can be done very efficiently with bit shifting:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// multiply MHz with power-of-two 2^5 = 32</span>
<span class="k">constexpr</span> <span class="kt">uint8_t</span> <span class="n">shift</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
<span class="c1">// 2.097MHz * 32  -&gt;  67 = 2.09375MHz  -&gt;  ~0.2% error</span>
<span class="n">constinit</span> <span class="kt">uint16_t</span> <span class="n">fcpu_MHz</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">round</span><span class="p">(</span><span class="mf">2.097</span><span class="n">f</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1ul</span> <span class="o">&lt;&lt;</span> <span class="n">shift</span><span class="p">));</span>
<span class="c1">// divide with simple bit shift</span>
<span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">us</span> <span class="o">*</span> <span class="n">fcpu_MHz</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">shift</span><span class="p">;</span>
</code></pre></div></div> <p>To keep the 32-bit multiplication from overflowing and to maintain at least 1s = 1’000’000µs of delay, we must limit the scaling so that 2<sup>32 - shift</sup> / max_fcpu ≥ 1s. A scalar of 32 is only good up to 134MHz, while the fastest STM32H7 running at 480MHz limits the scalar to only 8.</p> <p>For nanosecond delay we need a different algorithm, since the microcontrollers all run below 1GHz so one CPU cycle is several nanoseconds long. For example, the STM32F7 runnning at 216MHz will take ~4.6ns per cycle. To get the cycles fron a nanosecond input we would need to <em>divide</em>:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">float</span> <span class="n">ns_per_cycle</span> <span class="o">=</span> <span class="mf">4.6</span><span class="n">f</span><span class="p">;</span>
<span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">/</span> <span class="n">ns_per_cycle</span><span class="p">;</span>
</code></pre></div></div> <p>This is obviously way too slow to compute, but we first need to understand how to accurately <em>count</em> cycles to find a better solution to this problem.</p> <h1 id="counting-cycles"> <a href="#counting-cycles" class="anchor-head"></a> Counting Cycles </h1> <p>Wouldn’t it be nice if we could just delegate counting cycles to some hardware counter? Well, look no further than the Data Watchpoint and Trace (DWT) peripheral and its 32-bit <code class="language-plaintext highlighter-rouge">CYCCNT</code> free running at CPU frequency!</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Enable Tracing Debug Unit</span>
<span class="n">CoreDebug</span><span class="o">-&gt;</span><span class="n">DEMCR</span> <span class="o">|=</span> <span class="n">CoreDebug_DEMCR_TRCENA_Msk</span><span class="p">;</span>
<span class="c1">// Enable CPU cycle counter</span>
<span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CTRL</span> <span class="o">|=</span> <span class="n">DWT_CTRL_CYCCNTENA_Msk</span><span class="p">;</span>
</code></pre></div></div> <p>By reading <code class="language-plaintext highlighter-rouge">DWT-&gt;CYCCNT</code> once at the beginning and then comparing this constantly in a loop until the number of cycles have passed, we can implement a very simple, yet fairly accurate delay function:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">us</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">fcpu_MHz</span> <span class="o">*</span> <span class="n">us</span> <span class="o">&gt;&gt;</span> <span class="n">shift</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">now</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">now</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&gt;=</span> <span class="n">cycles</span><span class="p">)</span> <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Bonus win for this solution: time spent in interrupts during the delay is compensated for, since the hardware counter continues counting throughout.</p> <p>The delay function we use in modm only adds a memory fence to ensure reading the <code class="language-plaintext highlighter-rouge">start</code> count is not interleaved with other instructions and an overflow check when compiled in debug mode using <code class="language-plaintext highlighter-rouge">__builtin_umul_overflow</code> which triggers a <code class="language-plaintext highlighter-rouge">modm_assert</code>.</p> <h1 id="counting-loops"> <a href="#counting-loops" class="anchor-head"></a> Counting Loops </h1> <p>Unfortunately, the <code class="language-plaintext highlighter-rouge">DWT</code> peripheral is not implemented on ARM Cortex-M0(+) aka. ARMv6-M, so we have to count cycles a different way. We could use the <code class="language-plaintext highlighter-rouge">SysTick-&gt;VAL</code>, however it’s just a 24-bit counter, which limits us to ~16.8 million cycles: a ~1s delay at 16MHz or a maximum 35ms delay (!) at 480MHz. The SysTick is also often used for preemptive scheduling (in FreeRTOS) or to create a global clock (for software timers), so we cannot use it as a replacement.</p> <p>Instead we will count cycles the old fashioned way: in a tight assembly loop with a known timing. We use two 16-bit Thumb-2 instructions: subtraction and branch back. They are aligned so they fit into a single 32-bit instruction fetch and fill the pipeline entirely, giving us the maximum performance: 1 cycle for the subtraction and 2-cycles to branch back, so the loop takes 3 cycles total:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">us</span><span class="p">)</span> <span class="n">modm_fastcode</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">fcpu_MHz</span> <span class="o">*</span> <span class="n">us</span> <span class="o">&gt;&gt;</span> <span class="n">shift</span><span class="p">;</span>
    <span class="k">asm</span> <span class="k">volatile</span> <span class="p">(</span>
        <span class="s">".align 4"</span>          <span class="c1">// align for *one* 32-bit instruction fetch</span>
    <span class="s">"1:  subs.n %0, %0, #3"</span> <span class="c1">// subtract the loop cycles</span>
        <span class="s">"bpl.n  1b"</span>         <span class="c1">// loop while cycles are positive</span>
    <span class="o">::</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">cycles</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div> <p>The instruction fetch timings for executing directly from Flash depends on the CPU speed, the currently configured wait states and the state of the cache (if available and configured) and finally the branch speculation of the vendor cache implementation (this is not a core feature!). We therefore place the entire function into SRAM using the <code class="language-plaintext highlighter-rouge">modm_fastcode</code> attribute, which gives us <em>predictable</em> timings for instruction fetches across all Cortex-M cores, since we’re bypassing the Flash wait states and the (vendor supplied) cache entirely.</p> <p>Predictable, but not consistent: In my experiments I’ve discovered the loop to take 3 cycles on STM32{F3, G0, G4, L0, L4}, 4 cycles on STM32{L1, F0, F1, F4, F2} and just 1 cycle (yes!) on STM32F7. The timings depend on the (vendor defined) bus matrix implementation and the system configuration and are mainly about whether the Instruction Bus (I-Code) can access SRAM directly or whether the access is performed by the slower System Bus (S-Bus). The STM32F4 reference manual states in section 2.3.1 Embedded SRAM:</p> <blockquote> <p>The CPU can access the SRAM1, SRAM2, and SRAM3 through the System Bus or through the I-Code/D-Code buses when boot from SRAM is selected or when physical remap is selected. To get the max performance on SRAM execution, physical remap should be selected (boot or software selection).</p> </blockquote> <p>It seems that access through the I-Code takes 2-cycles, but the S-Bus takes 4-cycles, while the Cortex-M7 has a dual issue pipeline and native instruction cache with native branch prediction, so it’s just… really fast ? As confusing as it might be, at least the instruction fetch timing from SRAM is independent from the configured CPU frequency, which allows us to hardcode the loop cycles to subtract as an immediate value encoded in the instruction.</p> <p>The upper bound on the error is at most 3 cycles plus the error of the binary scaling, which together is good enough for our purpose. However, interrupts are not compensated, so the real delay may be significantly longer. If an accurate delay is absolutely necessary it can be wrapped into <code class="language-plaintext highlighter-rouge">modm::atomic::Lock</code> to disable interrupts during the delay.</p> <h1 id="counting-nanoseconds"> <a href="#counting-nanoseconds" class="anchor-head"></a> Counting Nanoseconds </h1> <p>To delay for nanoseconds we need to do something a little different, since the naive approach involves division, which would be way too slow. We can, however, approximate this division with a loop of subtractions! So we input the nanoseconds into the <code class="language-plaintext highlighter-rouge">subs bpl</code> loop and subtract the nanoseconds each loop takes: 1-4 cycles * fcpu<sup>-1</sup>. We store this value in SRAM and update it on every clock change:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">constexpr</span> <span class="kt">uint8_t</span> <span class="n">cycles_per_loop</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span> <span class="c1">// depends on device</span>
<span class="c1">// round the nanoseconds to minimize error</span>
<span class="kt">uint16_t</span> <span class="n">ns_per_loop</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">round</span><span class="p">(</span><span class="mf">1e9</span> <span class="o">*</span> <span class="n">cycles_per_loop</span> <span class="o">/</span> <span class="n">fcpu</span><span class="p">);</span>

<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ns</span><span class="p">)</span> <span class="n">modm_fastcode</span>
<span class="p">{</span>
    <span class="k">asm</span> <span class="k">volatile</span> <span class="p">(</span>
        <span class="s">".align 4"</span>          <span class="c1">// align for *one* 32-bit instruction fetch</span>
    <span class="s">"1:  subs.n %0, %0, %1"</span> <span class="c1">// subtract the nanoseconds per loop</span>
        <span class="s">"bpl.n  1b"</span>         <span class="c1">// loop while nanoseconds are positive</span>
    <span class="o">::</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">ns_per_loop</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div> <p>This works, however, there is a large overhead until execution arrives at the loop. The reason is that the compiler uses a <code class="language-plaintext highlighter-rouge">bl</code> (branch and link) instruction to jump to an address encoded as an <em>immediate value</em>. This is fast and efficient, however, it limits us to a relative address range of ±4MBs and our delay function in SRAM is waaaaay out there (SRAM starts @0x20000000 vs Flash @0x08000000). So the linker has to add a veneer, that does nothing else but jump further:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        modm::delay_ns(ns);
 8000214:   f002 fbf4   bl  8002a00 &lt;___ZN4modm8delay_nsEm_veneer&gt;

08002a00 &lt;___ZN4modm8delay_nsEm_veneer&gt;:
 8002a00:   f85f f000   ldr.w   pc, [pc]    ; 8002a04
 8002a04:   20000189    .word   0x20000189

20000188 &lt;_ZN4modm8delay_nsEm&gt;:
void modm_fastcode modm::delay_ns(uint32_t us)
</code></pre></div></div> <p>Since Flash access is very slow (up to a dozen wait states for fast devices), vendors supply a cache implementation with a limited buffer size (the ST “ART accelerator” cache has a max size of just 256-bit = 32 bytes!). So the jump to the veneer spends many cycles just waiting on the Flash and this time depends on the current clock configuration. Can we do better? Yes, with inline assembly!</p> <p>We move the actual implementation to <code class="language-plaintext highlighter-rouge">modm::platform::delay_ns</code> and then use an forced-inline forwarding function that uses the <code class="language-plaintext highlighter-rouge">blx</code> instruction to jump there directly instead of through a veneer:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm_always_inline</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ns</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">asm</span> <span class="k">volatile</span><span class="p">(</span>
        <span class="s">"mov r0, %0"</span> <span class="c1">// Required for the calling convention</span>
        <span class="s">"blx %1"</span>     <span class="c1">// Jump there directly</span>
        <span class="o">::</span> <span class="s">"r"</span> <span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="s">"l"</span> <span class="p">(</span><span class="n">modm</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">)</span> <span class="o">:</span> <span class="s">"r0"</span><span class="p">,</span> <span class="s">"r1"</span><span class="p">,</span> <span class="s">"r2"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>This reduces the overhead by eliminating the unnecessary jump and loading a literal that may already be in the instruction cache.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        modm::delay_ns(ns);
 80002c6:   4c25        ldr r4, [pc, #148]  ; 800035c
 80002ca:   4628        mov r0, r5
 80002cc:   47a0        blx r4

 800035c:   200001a9    .word   0x200001a9

200001a8 &lt;_ZN4modm8platform8delay_nsEm&gt;:
void modm_fastcode modm::platform::delay_ns(uint32_t us)
</code></pre></div></div> <p>However, we still need to actually compensate for this overhead, even if it’s just a few cycles, there should not be an offset in the delay function. To have maximum control we declare the function to be naked and implement the whole function in inline assembly:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">__attribute__</span><span class="p">((</span><span class="kr">naked</span><span class="p">,</span> <span class="n">aligned</span><span class="p">(</span><span class="mi">4</span><span class="p">)))</span> <span class="n">modm_fastcode</span>
<span class="n">modm</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ns</span><span class="p">)</span> <span class="c1">// passed in r0</span>
<span class="p">{</span>
    <span class="k">asm</span> <span class="k">volatile</span> <span class="p">(</span>
        <span class="s">"ldr.n  r2, =ns_per_loop"</span> <span class="c1">// address of ns_per_loop</span>
        <span class="s">"ldrh.n r2, [r2, #0]"</span>     <span class="c1">// load the actual 16-bit ns_per_loop value</span>

        <span class="s">"lsls.n r1, r2, #2"</span>       <span class="c1">// approximate overhead in ns by shift</span>
        <span class="s">"subs.n r0, r0, r1"</span>       <span class="c1">// subtract the overhead in nanoseconds</span>

    <span class="s">"1:  subs.n r0, r0, r2"</span>       <span class="c1">// subtract the nanoseconds per loop</span>
        <span class="s">"bpl.n  1b"</span>               <span class="c1">// loop while nanoseconds are positive</span>

        <span class="s">"bx lr"</span>                   <span class="c1">// return to execution</span>
    <span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>The overhead is measured experimentally and expressed in loops, which we can convert to nanoseconds by multiplying with the <code class="language-plaintext highlighter-rouge">ns_per_loop</code> variable. However the <code class="language-plaintext highlighter-rouge">umul</code> instruction requires passing the operands in registers, which would require an additional <code class="language-plaintext highlighter-rouge">mov</code> instruction for the <code class="language-plaintext highlighter-rouge">#4</code> immediate value, so instead we use the <code class="language-plaintext highlighter-rouge">lsl</code> instruction to shift the value left with the same effect. This limits the “overhead loop count” to powers of two, which in practice is not an issue.</p> <h1 id="counting-cycles-on-avr"> <a href="#counting-cycles-on-avr" class="anchor-head"></a> Counting Cycles on AVR </h1> <p>AVRs cannot change their CPU frequency at runtime, instead it is fixed at compile time via the <code class="language-plaintext highlighter-rouge">F_CPU</code> macro, so we don’t have to worry about that. The avr-lib provide implementations of <code class="language-plaintext highlighter-rouge">_delay_ms(double)</code> and <code class="language-plaintext highlighter-rouge">_delay_us(double)</code> in the <a href="https://www.nongnu.org/avr-libc/user-manual/group__util__delay.html"><code class="language-plaintext highlighter-rouge">&lt;util/delay.h&gt;</code> header</a>: However, <a href="https://www.nongnu.org/avr-libc/user-manual/delay_8h_source.html">the implementations use floating point math to calculate the delay cycles</a> for dynamic arguments. But fear not for there is a very sternly worded warning for passing a dynamic value to this incredible foot gun:</p> <blockquote> <p>In order for these functions to work as intended, compiler optimizations must be enabled, and the delay time must be an expression that is a known constant at compile-time. If these requirements are not met, the resulting delay will be much longer (and basically unpredictable), and applications that otherwise do not use floating-point calculations will experience severe code bloat by the floating-point library routines linked into the application.</p> </blockquote> <p>Of course this is a completely unacceptable implementation, since avr-gcc provides <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"><code class="language-plaintext highlighter-rouge">__builtin_constant_p()</code></a> to detect constant arguments and together with <a href="https://gcc.gnu.org/onlinedocs/gcc/AVR-Built-in-Functions.html"><code class="language-plaintext highlighter-rouge">__builtin_avr_delay_cycles(uint32_t)</code></a> can generates very accurate delays down to a single cycle for constant inputs at any clock rate.</p> <p>For a delay with a runtime argument we can loop over a 1ms or 1us constant delay and compensate for the loop overhead:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm_always_inline</span> <span class="c1">// &lt;- must be force inlined to work</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ms</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">ms</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">__builtin_constant_p</span><span class="p">(</span><span class="n">ms</span><span class="p">)</span> <span class="o">?</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">*</span> <span class="kt">double</span><span class="p">(</span><span class="n">ms</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">);</span>
        <span class="n">__builtin_avr_delay_cycles</span><span class="p">(</span><span class="n">cycles</span><span class="p">);</span>
    <span class="p">})</span> <span class="o">:</span> <span class="p">({</span>
        <span class="k">while</span><span class="p">(</span><span class="n">ms</span><span class="o">--</span><span class="p">)</span> <span class="n">__builtin_avr_delay_cycles</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">)</span> <span class="o">-</span> <span class="mi">10</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
<span class="n">modm_always_inline</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="kt">uint32_t</span> <span class="n">us</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">__builtin_constant_p</span><span class="p">(</span><span class="n">us</span><span class="p">)</span> <span class="o">?</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">*</span> <span class="kt">double</span><span class="p">(</span><span class="n">us</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">);</span>
        <span class="n">__builtin_avr_delay_cycles</span><span class="p">(</span><span class="n">cycles</span><span class="p">);</span>
    <span class="p">})</span> <span class="o">:</span> <span class="p">({</span>
        <span class="c1">// slightly lower overhead due to 16-bit delay  vvv</span>
        <span class="k">while</span><span class="p">(</span><span class="n">us</span><span class="o">--</span><span class="p">)</span> <span class="n">__builtin_avr_delay_cycles</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span> <span class="o">-</span> <span class="mi">6</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
</code></pre></div></div> <p>For dynamic nanosecond delay we approximate the division again with a shift, however, this time without multiplication, since that operation is very expensive on AVRs (dozens of cycles). The shift value is computed at compile time by rounding to the nearest power-of-two. The result is passed to the 4-cycle <code class="language-plaintext highlighter-rouge">_delay_loop_2(uint16_t)</code>, which does the actual delay. This solution only yields accurate delays at 16MHz (shift 8), 8MHz (shift 9) and 4MHz (shift 10), and has a significant error plus additional overhead of a few cycles for shifts &gt; 8. It’s not an ideal solution, but all other ideas yielded significantly worse results incl. using the Cortex-M method of subtraction in a loop.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modm_always_inline</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="kt">uint16_t</span> <span class="n">ns</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">__builtin_constant_p</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span> <span class="o">?</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">((</span><span class="n">F_CPU</span> <span class="o">*</span> <span class="kt">double</span><span class="p">(</span><span class="n">ns</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">);</span>
        <span class="n">__builtin_avr_delay_cycles</span><span class="p">(</span><span class="n">cycles</span><span class="p">);</span>
    <span class="p">})</span> <span class="o">:</span> <span class="p">({</span>
        <span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">loops</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">&gt;&gt;</span> <span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">loops</span><span class="p">)</span> <span class="n">_delay_loop_2</span><span class="p">(</span><span class="n">loops</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="using-stdchrono"> <a href="#using-stdchrono" class="anchor-head"></a> Using std::chrono </h1> <p>We want these functions to be compatible with <code class="language-plaintext highlighter-rouge">using namespace std::chrono_literals</code> so we overload the <code class="language-plaintext highlighter-rouge">modm::delay()</code> function with the appropriate durations. The conversion gets completely inlined and optimized away, so even for dynamic arguments there’s no code generated. A notable exception is the millisecond delay on Cortex-M, which gets converted to microseconds via a fast multiplication.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">Rep</span><span class="p">&gt;</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">Rep</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">nano</span><span class="o">&gt;</span> <span class="n">ns</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="k">auto</span> <span class="n">ns_</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">nanoseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ns</span><span class="p">)};</span>
    <span class="n">modm</span><span class="o">::</span><span class="n">delay_ns</span><span class="p">(</span><span class="n">ns_</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="p">}</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">Rep</span><span class="p">&gt;</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">Rep</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">micro</span><span class="o">&gt;</span> <span class="n">us</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="k">auto</span> <span class="n">us_</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">us</span><span class="p">)};</span>
    <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="n">us_</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="p">}</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">Rep</span><span class="p">&gt;</span>
<span class="kt">void</span> <span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">Rep</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">milli</span><span class="o">&gt;</span> <span class="n">ms</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// converted to us on Cortex-M, but AVR just forwards to modm::delay_ms</span>
    <span class="k">const</span> <span class="k">auto</span> <span class="n">us</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ms</span><span class="p">)};</span>
    <span class="n">modm</span><span class="o">::</span><span class="n">delay_us</span><span class="p">(</span><span class="n">us</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="evaluation"> <a href="#evaluation" class="anchor-head"></a> Evaluation </h1> <p>We can test the performance of our delay functions with <code class="language-plaintext highlighter-rouge">DWT-&gt;CYCCNT</code> on ARMv7-M which has a fixed 4 cycle overhead:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">time</span><span class="p">);</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">DWT</span><span class="o">-&gt;</span><span class="n">CYCCNT</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// 4 cycles overhead</span>
</code></pre></div></div> <p>ARMv6-M has no DWT module, so we use the <code class="language-plaintext highlighter-rouge">SysTick-&gt;VAL</code> instead. The value counts down (!) and gets reloaded to <code class="language-plaintext highlighter-rouge">SysTick-&gt;RELOAD</code> on underrun. We need to make sure the underrun does not happen during measurement so we set the <code class="language-plaintext highlighter-rouge">SysTick-&gt;VAL</code>before it.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">VAL</span> <span class="o">=</span> <span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">RELOAD</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">VAL</span><span class="p">;</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">time</span><span class="p">);</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">SysTick</span><span class="o">-&gt;</span><span class="n">VAL</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">start</span> <span class="o">-</span> <span class="n">stop</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// swapped subtraction!</span>
</code></pre></div></div> <p>And finally on AVRs we can use a 16-bit counter, here we use <code class="language-plaintext highlighter-rouge">TCNT1</code>, which limits the measurement (but not the delay function) to a maximum of 4ms @16MHz.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">TCNT1</span><span class="p">;</span>
<span class="n">modm</span><span class="o">::</span><span class="n">delay</span><span class="p">(</span><span class="n">time</span><span class="p">);</span>
<span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">TCNT1</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">uint16_t</span> <span class="n">cycles</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">;</span>
</code></pre></div></div> <p>In total 19 devices were tested by passing the delay function dynamic arguments in 10ns steps from 0ns to 10000ns. The Cortex-M devices were tested once at boot frequency and then again at their highest frequency. The AVR implementation is inlined in Flash, while the Cortex-M implementation jumps into RAM or I-Cache.</p> <table> <thead> <tr> <th style="text-align: left">Device</th> <th style="text-align: left">Core Type</th> <th style="text-align: right">Cycles per Loop</th> <th style="text-align: center">Minimum Cycles at Boot/High Frequency</th> <th style="text-align: right">Minimum Delay at Boot Frequency</th> <th style="text-align: right">Minimum Delay at High Frequency</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">ATMEGA2560</td> <td style="text-align: left">avr8</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right"> </td> </tr> <tr> <td style="text-align: left">SAMD21</td> <td style="text-align: left">cm0+</td> <td style="text-align: right">3</td> <td style="text-align: center">15</td> <td style="text-align: right"> </td> <td style="text-align: right">312ns @ 48 MHz</td> </tr> <tr> <td style="text-align: left">STM32F072</td> <td style="text-align: left">cm0</td> <td style="text-align: right">4</td> <td style="text-align: center">18/19</td> <td style="text-align: right">1125ns @ 16 MHz</td> <td style="text-align: right">395ns @ 48 MHz</td> </tr> <tr> <td style="text-align: left">STM32F091</td> <td style="text-align: left">cm0</td> <td style="text-align: right">4</td> <td style="text-align: center">18/19</td> <td style="text-align: right">1125ns @ 16 MHz</td> <td style="text-align: right">395ns @ 48 MHz</td> </tr> <tr> <td style="text-align: left">STM32F103</td> <td style="text-align: left">cm3</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">2000ns @ 8 MHz</td> <td style="text-align: right">250ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32F303</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13</td> <td style="text-align: right">1625ns @ 8 MHz</td> <td style="text-align: right">203ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32F334</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13</td> <td style="text-align: right">1625ns @ 8 MHz</td> <td style="text-align: right">203ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32F401</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">190ns @ 84 MHz</td> </tr> <tr> <td style="text-align: left">STM32F411</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">166ns @ 96 MHz</td> </tr> <tr> <td style="text-align: left">STM32F429</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">95ns @ 168 MHz</td> </tr> <tr> <td style="text-align: left">STM32F446</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">88ns @ 180 MHz</td> </tr> <tr> <td style="text-align: left">STM32F469</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">4</td> <td style="text-align: center">16</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">88ns @ 180 MHz</td> </tr> <tr> <td style="text-align: left">STM32F746</td> <td style="text-align: left">cm7fd</td> <td style="text-align: right">1</td> <td style="text-align: center">19</td> <td style="text-align: right">1187ns @ 16 MHz</td> <td style="text-align: right">87ns @ 216 MHz</td> </tr> <tr> <td style="text-align: left">STM32G071</td> <td style="text-align: left">cm0+</td> <td style="text-align: right">3</td> <td style="text-align: center">16/18</td> <td style="text-align: right">1000ns @ 16 MHz</td> <td style="text-align: right">281ns @ 64 MHz</td> </tr> <tr> <td style="text-align: left">STM32G474</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">17</td> <td style="text-align: right">1062ns @ 16 MHz</td> <td style="text-align: right">100ns @ 170 MHz</td> </tr> <tr> <td style="text-align: left">STM32L031</td> <td style="text-align: left">cm0</td> <td style="text-align: right">4</td> <td style="text-align: center">16/17</td> <td style="text-align: right">7629ns @ 2.097 MHz</td> <td style="text-align: right">531ns @ 32 MHz</td> </tr> <tr> <td style="text-align: left">STM32L152</td> <td style="text-align: left">cm3</td> <td style="text-align: right">4</td> <td style="text-align: center">16/17</td> <td style="text-align: right">7629ns @ 2.097 MHz</td> <td style="text-align: right">531ns @ 32 MHz</td> </tr> <tr> <td style="text-align: left">STM32L432</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13/15</td> <td style="text-align: right">812ns @ 16 MHz</td> <td style="text-align: right">162ns @ 80 MHz</td> </tr> <tr> <td style="text-align: left">STM32L476</td> <td style="text-align: left">cm4f</td> <td style="text-align: right">3</td> <td style="text-align: center">13/15</td> <td style="text-align: right">812ns @ 16 MHz</td> <td style="text-align: right">312ns @ 48 MHz</td> </tr> </tbody> </table> <p>The absolute minimum delay we can achieve is ~90ns and only on devices with a fast clock. You can clearly see the effect of the additional flash wait-states on some devices when they switch to high frequency</p> <p><img invertible="" src="ns_boot.svg" /></p> <p>The graph of the expected against the measured nanosecond delay at boot frequency shows several interesting points:</p> <ul> <li>The above mentioned minimum delays are very clear, particularly the 7.6us minimum delay for the STM32L0 and STM32L1 which boot at only ~2MHz.</li> <li>A ~600ns offset on AVR: This is not surprising as our implementation does not compensate for the calling overhead at all.</li> <li>A percentual error on AVR: At 16MHz the correct divider would be 250 for a 4-cycle loop, however, we’re shifting 8 = divide by 256, which is a 2.5% error. For other frequencies this error will be much higher.</li> <li>An offset on STM32F7: The correct offset compensation would be ~26 loops, however our “shift multiplication” can only do 16 or 32 loops, hence this offset. The Cortex-M7 has built-in branch prediction, perhaps that explains the small irregularity at the beginning.</li> <li>The coarseness of the stepping very clearly shows the different clock speeds and the cycles per loop.</li> <li>Most implemementations follow the ideal delay line very closely.</li> </ul> <p><img invertible="" src="ns_high.svg" /></p> <p>The graph of the expected against the measured nanosecond delay at the highest frequency shows that all implementations follow the ideal delay very precisely with only a very small error.</p> <p>The notable exception is the STM32F7 implementation, which has no offset anymore, but a significant ~7.5% error over time. Running at 216MHz a 1-cycle loop takes ~4.6ns which gets rounded up to 5ns which is then subtracted on every 1-cycle loop, thus yielding the full ~7.5% error. This creates an interesting failure mode for this algorithm: At around 667MHz the error is highest at 50%, since a 1.5ns per loop (=1ns/667MHz) delay must be rounded to either 1ns or 2ns. Currently no STM32 runs at that high a speed, however, the STM32H7 can run at at 400MHz, where the error would still be 25%.</p> <p>The delay implementation other devices has the same problem, however, since the loop takes 3-4 cycles the error is much smaller. For example, the 3-cycle loop on the STM32G4 running at a comparable 170MHz takes ~17.6ns (=3ns/170MHz) ≈ 18ns per loop, which is an error of just ~2%. In contrast, the 4-cycle loop on the 64MHz STM32F1 takes 62.5ns (=4ns/64MHz) ≈ 63ns with an error of ~1%.</p> <p>It becomes clear that the subtraction spreads the rounding error over 3-4 cycles which is comparable to fractional integer division. So an easy fix for the 1-cycle loop error on the STM32F7 is to lengthen the loop with some NOPs to reduce the overall error at the cost of resolution. I will leave this for a future self to solve though.</p> <p><img invertible="" src="ns_high_detail.svg" /></p> <p>Finally a detailed version of nanosecond delay at high frequencies from 0ns to 1000ns shows the same minimum delay and stepping properties as the boot frequency graph, showing that the same code is producing the same results at a faster speed too.</p> <p><img invertible="" src="us_boot.svg" /></p> <p>For completeness we’ve also measured microsecond delay from 0us to 1000us at boot frequency. The results are very accurate with a minimum delay of 1us on all devices except on the STM32L0 and STM32L1. They boot at 2.097MHz, where we use the fractional multiplication and shift to approximate 2.125MHz with an error of ~2%. Unfortunately on these devices millisecond delay will also have a 2% error, since they use microsecond delay under the hood as discussed.</p> <p>For microsecond delay at high frequency the measurements show no deviation at all, so that the graph is just a boring 1:1 line and therefore omitted.</p> <p>In conclusion, very accurate delays even at nanosecond resolution on AVR and Cortex-M devices are possible if the call overhead is compensated and the error over time is bound. However, the delay implementations are not as trivial as expected, but with some simple tricks can be made to fit.</p> <p><a href="https://xkcd.com/598"><img invertible="" src="xkcd.png" /></a></p> </div> </article> </main> <nav class="post-nav"> <a class="post-nav-item post-nav-prev" href="/modm-devices/" > <div class="nav-arrow">Previous</div> <span class="post-title">Introducing modm-devices: hardware descriptions for AVR and STM32 devices</span> </a> </nav> <footer class="footer"> <a class="footer_item" href="/feed.xml">rss</a> <span class="footer_item">&copy; 2021</span> <small class="footer_copyright"> <!-- Klisé Theme: https://github.com/piharpi/jekyll-klise --> <a href="https://github.com/piharpi/jekyll-klise" target="_blank" rel="noreferrer noopener" >klisé</a > theme on <a href="https://jekyllrb.com" target="_blank" rel="noreferrer noopener" >jekyll</a > </small> </footer> <script src="/assets/js/main.js" defer="defer"></script> </div> </body> </html>
